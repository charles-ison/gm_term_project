{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6596c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from options.test_options import TestOptions\n",
    "from data import DataLoader\n",
    "from models import create_model\n",
    "from models.layers.mesh_prepare import extract_features\n",
    "from util.writer import Writer\n",
    "from data.base_dataset import collate_fn\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "510373a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_attacked_model(model, dataset, writer, print_results):\n",
    "    writer.reset_counter()\n",
    "    attacked_model_outputs = []\n",
    "    \n",
    "    for i, data in enumerate(dataset):\n",
    "        model.set_input(data)\n",
    "        output, ncorrect, nexamples = model.test() \n",
    "        attacked_model_outputs.append(output)\n",
    "        writer.update_counter(ncorrect, nexamples)\n",
    "        \n",
    "        if(print_results and ncorrect == 0):\n",
    "            print(\"Label:  \" + str(data['label']))\n",
    "            print(\"pred: \" + str(torch.max(output, 1)[1]))\n",
    "            print(\"files_name: \" + str(data['mesh'][0].filename))\n",
    "        \n",
    "    writer.print_acc(-1, writer.acc)\n",
    "    return attacked_model_outputs \n",
    "    \n",
    "def find_new_vertex_index(vertices_edges, edge_index, old_vertex_index):\n",
    "    for new_vertex_index, new_vertex_edges in enumerate(vertices_edges):\n",
    "            for new_edge_index in new_vertex_edges:\n",
    "                if(new_edge_index == edge_index and new_vertex_index != old_vertex_index):\n",
    "                    return new_vertex_index\n",
    "                \n",
    "def get_random_walk(mesh, random_walk_size):\n",
    "    walk_steps = 0\n",
    "    random_walk_vertices = []\n",
    "    random_walk_indices = []\n",
    "    random.seed(walk_steps)\n",
    "    vertex_index = random.randint(0, len(mesh.vs)-1)\n",
    "    \n",
    "    while walk_steps < random_walk_size: \n",
    "        random_walk_vertices.append(mesh.vs[vertex_index])\n",
    "        random_walk_indices.append(vertex_index)        \n",
    "        walk_steps += 1  \n",
    "        \n",
    "        vertex_edges = mesh.ve[vertex_index]\n",
    "        random.seed(walk_steps+1)\n",
    "        random_edge_index = random.randint(0, len(vertex_edges)-1)  \n",
    "        new_edge_index = vertex_edges[random_edge_index]\n",
    "        vertex_index = find_new_vertex_index(mesh.ve, new_edge_index, random_walk_indices[-1])\n",
    "        \n",
    "        #Prevents random walk from crossing over itself\n",
    "        count_of_vertex_edge_attempts = 0\n",
    "        walk_steps_backwards = 0\n",
    "        while(vertex_index in random_walk_indices):\n",
    "            if(count_of_vertex_edge_attempts >= len(vertex_edges)-1):\n",
    "                walk_steps_backwards += 1\n",
    "                go_back_to_index = walk_steps-walk_steps_backwards\n",
    "                \n",
    "                if(go_back_to_index == 0):\n",
    "                    # Trying again, mesh seems to be broken?\n",
    "                    return get_random_walk(mesh, random_walk_size)\n",
    "                \n",
    "                vertex_edges = mesh.ve[random_walk_indices[go_back_to_index]]\n",
    "                count_of_vertex_edge_attempts = 0\n",
    "                \n",
    "            random_edge_index = (random_edge_index + 1) % len(vertex_edges)\n",
    "            new_edge_index = vertex_edges[random_edge_index]\n",
    "            vertex_index = find_new_vertex_index(mesh.ve, new_edge_index, random_walk_indices[-1])\n",
    "            count_of_vertex_edge_attempts += 1        \n",
    "    \n",
    "    return torch.FloatTensor(random_walk_vertices), random_walk_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b11d117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_imitating_network(imitating_nn, criterion, optimizer, random_walk_vertices, labels, attacked_model_outputs):\n",
    "\n",
    "    output = imitating_nn(random_walk_vertices)\n",
    "    loss = criterion(output, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step() \n",
    "    \n",
    "    _, predictions = torch.max(output.data, 1)\n",
    "    num_correct = (predictions == labels).sum().item()\n",
    "    \n",
    "    return output, loss.item(), num_correct\n",
    "\n",
    "def use_imitating_network_for_attack(imitating_nn, criterion, optimizer, random_walk_vertices, labels, attacked_model_outputs):\n",
    "\n",
    "    output = imitating_nn(random_walk_vertices)\n",
    "    loss = criterion(F.softmax(output, dim=1), F.softmax(attacked_model_outputs, dim=1))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step() \n",
    "    \n",
    "    _, predictions = torch.max(output.data, 1)\n",
    "    num_correct = (predictions == labels).sum().item()\n",
    "    \n",
    "    return output, loss.item(), num_correct, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c93047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        combined = torch.cat((input, hidden), -1)\n",
    "        hidden = self.i2h(combined)\n",
    "        output = self.i2o(combined)\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "class Imitating_NN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Imitating_NN, self).__init__()\n",
    "        \n",
    "        self.scaling_factor = 10\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        self.first_linear = nn.Linear(input_size, 2*self.scaling_factor*input_size)\n",
    "        self.second_linear = nn.Linear(2*self.scaling_factor*input_size, self.scaling_factor*input_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.rnn = RNN(self.scaling_factor*input_size, self.scaling_factor*input_size, self.scaling_factor*input_size)\n",
    "        self.third_linear = nn.Linear(self.scaling_factor*input_size, 2*self.scaling_factor*input_size)\n",
    "        self.fourth_linear = nn.Linear(2*self.scaling_factor*input_size, output_size)\n",
    "        \n",
    "    def forward(self, random_walk_vertices):\n",
    "        \n",
    "        output = self.first_linear(random_walk_vertices)\n",
    "        output = self.second_linear(output)\n",
    "        output = self.relu(output)\n",
    "        \n",
    "        hidden = self.rnn.initHidden()\n",
    "        for step in output:\n",
    "            output, hidden = self.rnn(torch.reshape(step, (1, self.input_size*self.scaling_factor)), hidden)\n",
    "            \n",
    "        output = self.third_linear(output)\n",
    "        output = self.fourth_linear(output)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba35fae",
   "metadata": {},
   "source": [
    "# Orchestration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c07fac7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded mean / std from cache\n",
      "loading the model from ./checkpoints/shrec16/latest_net.pth\n"
     ]
    }
   ],
   "source": [
    "testing_opt = TestOptions().parse()\n",
    "\n",
    "testing_opt.serial_batches = True\n",
    "dataloader = DataLoader(testing_opt)\n",
    "mesh_cnn = create_model(testing_opt)\n",
    "opt_writer = Writer(testing_opt)\n",
    "\n",
    "shift_weight = 0.3\n",
    "num_vertices_to_move = 5\n",
    "random_walk_size = 50\n",
    "num_categories = 30\n",
    "num_vertice_coordinates = 3\n",
    "imitating_nn = Imitating_NN(num_vertice_coordinates, num_categories)\n",
    "kld_criterion = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "ce_criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(imitating_nn.parameters(), lr = 0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efa9fddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: -1, TEST ACC: [99.167 %]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Record testing accuracy before attack\n",
    "attacked_model_outputs = test_attacked_model(mesh_cnn, dataloader, opt_writer, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43ee32ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded mean / std from cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ts/sy6vbbcs1vdbgtnds0713g6w0000gq/T/ipykernel_65376/812503903.py:63: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  return torch.FloatTensor(random_walk_vertices), random_walk_indices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 418.0003640651703 , accuracy: 0.0\n",
      "epoch: 1, loss: 412.8466935157776 , accuracy: 0.0\n",
      "epoch: 2, loss: 412.38605999946594 , accuracy: 0.0\n",
      "epoch: 3, loss: 410.9580202102661 , accuracy: 0.0\n",
      "epoch: 4, loss: 409.9135329723358 , accuracy: 0.016666666666666666\n",
      "epoch: 5, loss: 406.6867673397064 , accuracy: 0.016666666666666666\n",
      "epoch: 6, loss: 406.7157185077667 , accuracy: 0.0\n",
      "epoch: 7, loss: 410.45795035362244 , accuracy: 0.016666666666666666\n",
      "epoch: 8, loss: 410.97475814819336 , accuracy: 0.016666666666666666\n",
      "epoch: 9, loss: 405.3257279396057 , accuracy: 0.05\n",
      "epoch: 10, loss: 401.6131776571274 , accuracy: 0.06666666666666667\n",
      "epoch: 11, loss: 398.68185555934906 , accuracy: 0.041666666666666664\n",
      "epoch: 12, loss: 393.52218449115753 , accuracy: 0.05\n",
      "epoch: 13, loss: 388.47274899482727 , accuracy: 0.058333333333333334\n",
      "epoch: 14, loss: 384.17047357559204 , accuracy: 0.075\n",
      "epoch: 15, loss: 380.5140552520752 , accuracy: 0.1\n",
      "epoch: 16, loss: 377.54541516304016 , accuracy: 0.09166666666666666\n",
      "epoch: 17, loss: 374.22278916835785 , accuracy: 0.10833333333333334\n",
      "epoch: 18, loss: 370.2248396873474 , accuracy: 0.11666666666666667\n",
      "epoch: 19, loss: 366.2614902853966 , accuracy: 0.10833333333333334\n",
      "epoch: 20, loss: 362.8980162143707 , accuracy: 0.09166666666666666\n",
      "epoch: 21, loss: 359.8992297053337 , accuracy: 0.10833333333333334\n",
      "epoch: 22, loss: 357.0349619984627 , accuracy: 0.11666666666666667\n",
      "epoch: 23, loss: 353.90488731861115 , accuracy: 0.09166666666666666\n",
      "epoch: 24, loss: 350.74027502536774 , accuracy: 0.09166666666666666\n",
      "epoch: 25, loss: 347.4601290822029 , accuracy: 0.10833333333333334\n",
      "epoch: 26, loss: 344.05705147981644 , accuracy: 0.13333333333333333\n",
      "epoch: 27, loss: 340.28282099962234 , accuracy: 0.13333333333333333\n",
      "epoch: 28, loss: 336.23064774274826 , accuracy: 0.15\n",
      "epoch: 29, loss: 331.9208120405674 , accuracy: 0.15833333333333333\n",
      "epoch: 30, loss: 327.39974269270897 , accuracy: 0.15833333333333333\n",
      "epoch: 31, loss: 322.7083743214607 , accuracy: 0.15\n",
      "epoch: 32, loss: 317.9664036035538 , accuracy: 0.15833333333333333\n",
      "epoch: 33, loss: 313.14228078722954 , accuracy: 0.2\n",
      "epoch: 34, loss: 308.3642162978649 , accuracy: 0.225\n",
      "epoch: 35, loss: 303.5652299076319 , accuracy: 0.23333333333333334\n",
      "epoch: 36, loss: 298.62427893280983 , accuracy: 0.225\n",
      "epoch: 37, loss: 293.5323923379183 , accuracy: 0.225\n",
      "epoch: 38, loss: 288.778027549386 , accuracy: 0.23333333333333334\n",
      "epoch: 39, loss: 283.95497597754 , accuracy: 0.24166666666666667\n",
      "epoch: 40, loss: 279.4481961876154 , accuracy: 0.26666666666666666\n",
      "epoch: 41, loss: 274.94940623641014 , accuracy: 0.26666666666666666\n",
      "epoch: 42, loss: 271.1699425727129 , accuracy: 0.26666666666666666\n",
      "epoch: 43, loss: 267.00005259364843 , accuracy: 0.2833333333333333\n",
      "epoch: 44, loss: 263.2553428038955 , accuracy: 0.2916666666666667\n",
      "epoch: 45, loss: 258.5415680781007 , accuracy: 0.26666666666666666\n",
      "epoch: 46, loss: 254.03935892879963 , accuracy: 0.2833333333333333\n",
      "epoch: 47, loss: 248.90170721709728 , accuracy: 0.3\n",
      "epoch: 48, loss: 243.98978830128908 , accuracy: 0.31666666666666665\n",
      "epoch: 49, loss: 239.11947056651115 , accuracy: 0.325\n",
      "epoch: 50, loss: 233.7558216303587 , accuracy: 0.35833333333333334\n",
      "epoch: 51, loss: 228.63236052170396 , accuracy: 0.36666666666666664\n",
      "epoch: 52, loss: 223.46476864814758 , accuracy: 0.39166666666666666\n",
      "epoch: 53, loss: 218.0805012062192 , accuracy: 0.4166666666666667\n",
      "epoch: 54, loss: 212.009767819196 , accuracy: 0.425\n",
      "epoch: 55, loss: 206.18827774003148 , accuracy: 0.4583333333333333\n",
      "epoch: 56, loss: 199.96478285640478 , accuracy: 0.4583333333333333\n",
      "epoch: 57, loss: 193.84784981049597 , accuracy: 0.475\n",
      "epoch: 58, loss: 187.66599443927407 , accuracy: 0.48333333333333334\n",
      "epoch: 59, loss: 181.95711413770914 , accuracy: 0.5083333333333333\n",
      "epoch: 60, loss: 176.34372457116842 , accuracy: 0.5\n",
      "epoch: 61, loss: 170.38748260959983 , accuracy: 0.5083333333333333\n",
      "epoch: 62, loss: 164.83440455421805 , accuracy: 0.525\n",
      "epoch: 63, loss: 158.77121874317527 , accuracy: 0.575\n",
      "epoch: 64, loss: 153.54202834889293 , accuracy: 0.6\n",
      "epoch: 65, loss: 147.28785019461066 , accuracy: 0.6083333333333333\n",
      "epoch: 66, loss: 141.6433133073151 , accuracy: 0.6166666666666667\n",
      "epoch: 67, loss: 136.67051014862955 , accuracy: 0.625\n",
      "epoch: 68, loss: 131.31252474803478 , accuracy: 0.65\n",
      "epoch: 69, loss: 126.75311307283118 , accuracy: 0.6666666666666666\n",
      "epoch: 70, loss: 120.9052613042295 , accuracy: 0.675\n",
      "epoch: 71, loss: 115.26661641150713 , accuracy: 0.6916666666666667\n",
      "epoch: 72, loss: 110.70273416326381 , accuracy: 0.725\n",
      "epoch: 73, loss: 106.25328498170711 , accuracy: 0.75\n",
      "epoch: 74, loss: 101.66840289533138 , accuracy: 0.775\n",
      "epoch: 75, loss: 97.22365097235888 , accuracy: 0.7916666666666666\n",
      "epoch: 76, loss: 95.19686333788559 , accuracy: 0.7916666666666666\n",
      "epoch: 77, loss: 96.18579646846047 , accuracy: 0.8\n",
      "epoch: 78, loss: 137.14877643401996 , accuracy: 0.6083333333333333\n",
      "epoch: 79, loss: 106.60785793588724 , accuracy: 0.7416666666666667\n",
      "epoch: 80, loss: 88.3118026679831 , accuracy: 0.8\n",
      "epoch: 81, loss: 71.71813357427163 , accuracy: 0.8666666666666667\n",
      "epoch: 82, loss: 66.737959279395 , accuracy: 0.875\n",
      "epoch: 83, loss: 63.30677430672222 , accuracy: 0.8916666666666667\n",
      "epoch: 84, loss: 59.08449048442708 , accuracy: 0.9\n",
      "epoch: 85, loss: 57.42192042899842 , accuracy: 0.9083333333333333\n",
      "epoch: 86, loss: 53.63082275713532 , accuracy: 0.9166666666666666\n",
      "epoch: 87, loss: 51.78652597916516 , accuracy: 0.925\n",
      "epoch: 88, loss: 48.24108352159237 , accuracy: 0.9333333333333333\n",
      "epoch: 89, loss: 45.306776744713716 , accuracy: 0.9333333333333333\n",
      "epoch: 90, loss: 41.70355809811008 , accuracy: 0.9416666666666667\n",
      "epoch: 91, loss: 39.152413797706686 , accuracy: 0.9583333333333334\n",
      "epoch: 92, loss: 36.33044531952146 , accuracy: 0.9583333333333334\n",
      "epoch: 93, loss: 35.47798730497743 , accuracy: 0.9666666666666667\n",
      "epoch: 94, loss: 31.973060822439038 , accuracy: 0.975\n",
      "epoch: 95, loss: 117.17258229535219 , accuracy: 0.7583333333333333\n",
      "epoch: 96, loss: 161.38303785116295 , accuracy: 0.575\n",
      "epoch: 97, loss: 70.7453755863744 , accuracy: 0.8166666666666667\n",
      "epoch: 98, loss: 33.08226519939353 , accuracy: 0.9583333333333334\n",
      "epoch: 99, loss: 22.48173654827633 , accuracy: 0.9916666666666667\n"
     ]
    }
   ],
   "source": [
    "# Beginning Random Walk Attack\n",
    "dataloader = DataLoader(testing_opt)\n",
    "\n",
    "# Training Imitation Network\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "    epoch_num_correct = 0\n",
    "    epoch_num_samples = 0;\n",
    "    for i, data in enumerate(dataloader):\n",
    "        mesh = data[\"mesh\"][0]\n",
    "        label = torch.from_numpy(data[\"label\"])\n",
    "        \n",
    "        random_walk_vertices, random_walk_indices = get_random_walk(mesh, random_walk_size)\n",
    "        \n",
    "        imitating_nn_output, loss, num_correct = train_imitating_network(imitating_nn, ce_criterion, optimizer, random_walk_vertices, label, attacked_model_outputs[i])\n",
    "        \n",
    "        epoch_num_samples += label.size(dim=-1)\n",
    "        epoch_loss += loss\n",
    "        epoch_num_correct += num_correct\n",
    "    \n",
    "    accuracy = epoch_num_correct / epoch_num_samples\n",
    "    print(\"epoch: \" + str(epoch) + \", loss: \" + str(epoch_loss), \", accuracy: \" + str(accuracy))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9f6248d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded mean / std from cache\n"
     ]
    }
   ],
   "source": [
    "# Moving Vertices\n",
    "dataloader = DataLoader(testing_opt)\n",
    "\n",
    "def gradients_magnitude(vertices):\n",
    "    return vertices[1][0] ** 2 + vertices[1][1] ** 2 + vertices[1][2] ** 2\n",
    "    \n",
    "overridden_meshes = []\n",
    "for i, data in enumerate(dataloader):\n",
    "        mesh = data[\"mesh\"][0]\n",
    "        random_walk_vertices, random_walk_indices = get_random_walk(mesh, random_walk_size)\n",
    "        label = torch.from_numpy(data[\"label\"])\n",
    "    \n",
    "        random_walk_vertices.requires_grad = True\n",
    "        imitating_nn_output, loss, num_correct, pred = use_imitating_network_for_attack(imitating_nn, kld_criterion, optimizer, random_walk_vertices, label, attacked_model_outputs[i])\n",
    "        \n",
    "        gradients_dict = dict(zip(random_walk_indices, random_walk_vertices.grad))\n",
    "        gradients_dict = dict(sorted(gradients_dict.items(), key = gradients_magnitude))\n",
    "        \n",
    "        max_grad = torch.max(random_walk_vertices.grad.flatten(), 0)[0].item()\n",
    "        min_grad = torch.min(random_walk_vertices.grad.flatten(), 0)[0].item()\n",
    "        \n",
    "        num_vertices_changed = 0\n",
    "        while(num_vertices_changed < num_vertices_to_move):\n",
    "            \n",
    "            gradient_entry = gradients_dict.popitem()\n",
    "            index = gradient_entry[0]\n",
    "            gradients = gradient_entry[1]\n",
    "            \n",
    "            mesh.vs[index][0] += ((2 * shift_weight * (gradients[0]-min_grad) / (max_grad-min_grad)) - shift_weight)\n",
    "            mesh.vs[index][1] += ((2 * shift_weight * (gradients[1]-min_grad) / (max_grad-min_grad)) - shift_weight)\n",
    "            mesh.vs[index][2] += ((2 * shift_weight * (gradients[2]-min_grad) / (max_grad-min_grad)) - shift_weight)\n",
    "            \n",
    "            #mesh.vs[index][0] += gradients[0]\n",
    "            #mesh.vs[index][1] += gradients[1]\n",
    "            #mesh.vs[index][2] += gradients[2]\n",
    "    \n",
    "            num_vertices_changed += 1\n",
    "                \n",
    "        mesh.features = extract_features(mesh)\n",
    "        overridden_meshes.append(mesh)\n",
    "        new_file_name = \"datasets/random_walks/\" + mesh.filename\n",
    "        mesh.export(file=new_file_name)\n",
    "\n",
    "dataloader.dataloader.dataset.override_meshes(overridden_meshes) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bb4f4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [7]\n",
      "pred: tensor([5])\n",
      "files_name: T156.obj\n",
      "Label:  [7]\n",
      "pred: tensor([5])\n",
      "files_name: T576.obj\n",
      "Label:  [8]\n",
      "pred: tensor([2])\n",
      "files_name: T434.obj\n",
      "Label:  [8]\n",
      "pred: tensor([2])\n",
      "files_name: T598.obj\n",
      "Label:  [10]\n",
      "pred: tensor([23])\n",
      "files_name: T476.obj\n",
      "Label:  [11]\n",
      "pred: tensor([5])\n",
      "files_name: T504.obj\n",
      "Label:  [11]\n",
      "pred: tensor([6])\n",
      "files_name: T582.obj\n",
      "Label:  [13]\n",
      "pred: tensor([17])\n",
      "files_name: T102.obj\n",
      "Label:  [13]\n",
      "pred: tensor([17])\n",
      "files_name: T530.obj\n",
      "Label:  [14]\n",
      "pred: tensor([9])\n",
      "files_name: T105.obj\n",
      "Label:  [14]\n",
      "pred: tensor([9])\n",
      "files_name: T4.obj\n",
      "Label:  [14]\n",
      "pred: tensor([9])\n",
      "files_name: T471.obj\n",
      "Label:  [14]\n",
      "pred: tensor([15])\n",
      "files_name: T478.obj\n",
      "Label:  [16]\n",
      "pred: tensor([5])\n",
      "files_name: T343.obj\n",
      "Label:  [19]\n",
      "pred: tensor([9])\n",
      "files_name: T21.obj\n",
      "Label:  [19]\n",
      "pred: tensor([6])\n",
      "files_name: T404.obj\n",
      "Label:  [19]\n",
      "pred: tensor([15])\n",
      "files_name: T519.obj\n",
      "Label:  [19]\n",
      "pred: tensor([9])\n",
      "files_name: T542.obj\n",
      "Label:  [22]\n",
      "pred: tensor([9])\n",
      "files_name: T505.obj\n",
      "Label:  [24]\n",
      "pred: tensor([2])\n",
      "files_name: T114.obj\n",
      "Label:  [24]\n",
      "pred: tensor([8])\n",
      "files_name: T435.obj\n",
      "Label:  [25]\n",
      "pred: tensor([18])\n",
      "files_name: T104.obj\n",
      "Label:  [25]\n",
      "pred: tensor([4])\n",
      "files_name: T353.obj\n",
      "Label:  [25]\n",
      "pred: tensor([4])\n",
      "files_name: T492.obj\n",
      "Label:  [25]\n",
      "pred: tensor([4])\n",
      "files_name: T498.obj\n",
      "Label:  [27]\n",
      "pred: tensor([1])\n",
      "files_name: T108.obj\n",
      "Label:  [27]\n",
      "pred: tensor([21])\n",
      "files_name: T414.obj\n",
      "Label:  [28]\n",
      "pred: tensor([5])\n",
      "files_name: T540.obj\n",
      "Label:  [29]\n",
      "pred: tensor([6])\n",
      "files_name: T147.obj\n",
      "Label:  [29]\n",
      "pred: tensor([17])\n",
      "files_name: T461.obj\n",
      "Label:  [29]\n",
      "pred: tensor([6])\n",
      "files_name: T581.obj\n",
      "Label:  [29]\n",
      "pred: tensor([9])\n",
      "files_name: T586.obj\n",
      "epoch: -1, TEST ACC: [73.333 %]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Record testing accuracy after random walk attack\n",
    "attacked_model_outputs = test_attacked_model(mesh_cnn, dataloader, opt_writer, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49ff849f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded mean / std from cache\n"
     ]
    }
   ],
   "source": [
    "# Random Pertubation Attack\n",
    "dataloader = DataLoader(testing_opt)\n",
    "overridden_meshes = []\n",
    "for i, data in enumerate(dataloader):\n",
    "    \n",
    "    mesh = data[\"mesh\"][0]\n",
    "    num_random_changes = 0\n",
    "    \n",
    "    while(num_random_changes < num_vertices_to_move):\n",
    "        \n",
    "        random_vertex_index = random.randint(0, len(mesh.vs)-1)    \n",
    "        mesh.vs[random_vertex_index][0] += random.uniform(-shift_weight, shift_weight)\n",
    "        mesh.vs[random_vertex_index][1] += random.uniform(-shift_weight, shift_weight)\n",
    "        mesh.vs[random_vertex_index][2] += random.uniform(-shift_weight, shift_weight)\n",
    "        num_random_changes += 1\n",
    "    \n",
    "    mesh.features = extract_features(mesh)\n",
    "    overridden_meshes.append(mesh)\n",
    "    new_file_name = \"datasets/random_pertubations/\" + mesh.filename\n",
    "    mesh.export(file=new_file_name)\n",
    "\n",
    "dataloader.dataloader.dataset.override_meshes(overridden_meshes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "955ac5db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [7]\n",
      "pred: tensor([5])\n",
      "files_name: T576.obj\n",
      "Label:  [8]\n",
      "pred: tensor([2])\n",
      "files_name: T598.obj\n",
      "Label:  [14]\n",
      "pred: tensor([9])\n",
      "files_name: T105.obj\n",
      "Label:  [19]\n",
      "pred: tensor([22])\n",
      "files_name: T404.obj\n",
      "Label:  [24]\n",
      "pred: tensor([9])\n",
      "files_name: T435.obj\n",
      "Label:  [25]\n",
      "pred: tensor([4])\n",
      "files_name: T492.obj\n",
      "Label:  [28]\n",
      "pred: tensor([5])\n",
      "files_name: T540.obj\n",
      "Label:  [29]\n",
      "pred: tensor([19])\n",
      "files_name: T461.obj\n",
      "Label:  [29]\n",
      "pred: tensor([19])\n",
      "files_name: T581.obj\n",
      "Label:  [29]\n",
      "pred: tensor([9])\n",
      "files_name: T586.obj\n",
      "epoch: -1, TEST ACC: [91.667 %]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Record testing accuracy after random pertubation attack\n",
    "attacked_model_outputs = test_attacked_model(mesh_cnn, dataloader, opt_writer, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dbf252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
